import random
import time
from datetime import datetime, timedelta
from typing import Any

import requests


class HeadHunterAPI:
    BASE_URL = "https://api.hh.ru"

    def __init__(self, employers: list[str]) -> None:
        self.employers = employers
        self.session = requests.Session()
        self.session.headers.update(
            {"User-Agent": "Mozilla/5.0 (compatible; HH-Parser/1.0)"}
        )

    def _get(self, url: str, params: dict[str, Any] | None = None) -> dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç GET-–∑–∞–ø—Ä–æ—Å —Å retry, throttling –∏ backoff."""
        retries = 8
        base_delay = 0.2  # –±–∞–∑–æ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏

        for attempt in range(retries):
            try:
                response = self.session.get(url, params=params)

                # –µ—Å–ª–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ –∏–ª–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞
                if response.status_code in (500, 502, 503, 504, 429, 403):
                    wait = (2**attempt) + random.random()
                    print(
                        f"‚ö†Ô∏è –û—à–∏–±–∫–∞ {response.status_code} –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {url}, "
                        f"–ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {wait:.1f} —Å–µ–∫..."
                    )
                    time.sleep(wait)
                    continue

                response.raise_for_status()
                time.sleep(base_delay)  # –ø–∞—É–∑–∞ –º–µ–∂–¥—É —É—Å–ø–µ—à–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
                return response.json()

            except requests.RequestException as e:
                wait = (2**attempt) + random.random()
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ {e}, –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {wait:.1f} —Å–µ–∫...")
                time.sleep(wait)

        raise RuntimeError(
            f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ {retries} –ø–æ–ø—ã—Ç–æ–∫: {url}"
        )

    def get_employer(self, employer_id: str) -> dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª–µ –ø–æ id."""
        url = f"{self.BASE_URL}/employers/{employer_id}"
        return self._get(url)

    def get_vacancies(
        self, employer_id: str, employer_name: str, found: int
    ) -> list[dict[str, Any]]:
        url = f"{self.BASE_URL}/vacancies"
        vacancies = []
        seen_ids = set()

        # 1. –ü–µ—Ä–≤–∞—è –ø–∞—Ä—Ç–∏—è (–¥–æ 2000, –±–µ–∑ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤)
        for page in range(20):
            params = {
                "employer_id": employer_id,
                "per_page": 100,
                "page": page,
                "order_by": "publication_time",
            }
            data = self._get(url, params)
            items = data.get("items", [])
            if not items:
                break
            for item in items:
                if item["id"] not in seen_ids:
                    vacancies.append(item)
                    seen_ids.add(item["id"])

        if len(vacancies) >= found or not vacancies:
            return vacancies

        print(f"üîé {employer_name}: —Å–æ–±—Ä–∞–Ω–æ {len(vacancies)} / {found}")

        # 2. –î–∞–ª—å—à–µ –∏–¥—ë–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        last_date = vacancies[-1]["published_at"]
        date_to = datetime.fromisoformat(last_date.replace("Z", "+00:00"))

        step = timedelta(days=30)
        min_step = timedelta(minutes=30)  # –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —à–∞–≥
        max_step = timedelta(days=90)

        while len(vacancies) < found:
            remaining = found - len(vacancies)

            # –µ—Å–ª–∏ –æ—Å—Ç–∞—Ç–æ–∫ –º–µ–Ω—å—à–µ 2000 ‚Üí –±–µ—Ä—ë–º max_days –∏ —Å–æ–±–∏—Ä–∞–µ–º —Ö–≤–æ—Å—Ç
            if remaining <= 2000:
                date_from = date_to - max_step
                probe_params = {
                    "employer_id": employer_id,
                    "per_page": 1,
                    "page": 0,
                    "order_by": "publication_time",
                    "date_from": date_from.isoformat(),
                    "date_to": date_to.isoformat(),
                }
                probe_data = self._get(url, probe_params)
                interval_found = probe_data.get("found", 0)

                if interval_found > 2000 and step > min_step:
                    step = step / 2
                    continue

                for page in range(min(20, probe_data.get("pages", 0))):
                    params = {
                        "employer_id": employer_id,
                        "per_page": 100,
                        "page": page,
                        "order_by": "publication_time",
                        "date_from": date_from.isoformat(),
                        "date_to": date_to.isoformat(),
                    }
                    data = self._get(url, params)
                    items = data.get("items", [])
                    if not items:
                        break
                    for item in items:
                        if item["id"] not in seen_ids:
                            vacancies.append(item)
                            seen_ids.add(item["id"])
                break

            # –ø—Ä–æ–±–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            date_from = date_to - step
            probe_params = {
                "employer_id": employer_id,
                "per_page": 1,
                "page": 0,
                "order_by": "publication_time",
                "date_from": date_from.isoformat(),
                "date_to": date_to.isoformat(),
            }
            probe_data = self._get(url, probe_params)
            interval_found = probe_data.get("found", 0)

            if interval_found > 2000 and step > min_step:
                step = step / 2
                continue

            if interval_found < 1500 and step < max_step:
                step = step * 1.5
                continue

            # –µ—Å–ª–∏ 1‚Äì2000 ‚Üí —Å—Ä–∞–∑—É —Å–æ–±–∏—Ä–∞–µ–º
            for page in range(min(20, probe_data.get("pages", 0))):
                params = {
                    "employer_id": employer_id,
                    "per_page": 100,
                    "page": page,
                    "order_by": "publication_time",
                    "date_from": date_from.isoformat(),
                    "date_to": date_to.isoformat(),
                }
                data = self._get(url, params)
                items = data.get("items", [])
                if not items:
                    break
                for item in items:
                    if item["id"] not in seen_ids:
                        vacancies.append(item)
                        seen_ids.add(item["id"])

            print(f"üîé {employer_name}: —Å–æ–±—Ä–∞–Ω–æ {len(vacancies)} / {found}")

            # —Å–º–µ—â–∞–µ–º –æ–∫–Ω–æ –Ω–∞–∑–∞–¥
            date_to = date_from + timedelta(seconds=1)

        vacancies = list({v["id"]: v for v in vacancies}.values())

        return vacancies

    def collect_data(self) -> dict[str, list[dict[str, Any]]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª–µ–π –∏ –∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π."""
        data: dict[str, list[dict[str, Any]]] = {"employers": [], "vacancies": []}

        for emp_id in self.employers:
            employer = self.get_employer(emp_id)
            if not employer:
                print(f"‚ùå –†–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å {emp_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                continue

            emp_name = employer["name"]
            declared_open = employer.get("open_vacancies", 0)

            # —Å–Ω–∞—á–∞–ª–∞ –¥–µ–ª–∞–µ–º –ø—Ä–æ–±–Ω—ã–π –∑–∞–ø—Ä–æ—Å, —á—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å found
            url = f"{self.BASE_URL}/vacancies"
            probe_params = {"employer_id": emp_id, "per_page": 1}
            probe_data = self._get(url, probe_params)
            found = probe_data.get("found", 0)

            vacancies = self.get_vacancies(emp_id, emp_name, found)

            data["employers"].append(
                {
                    "employer_id": employer["id"],
                    "name": emp_name,
                    "url": employer["alternate_url"],
                    "open_vacancies": found,  # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º–µ–Ω–Ω–æ —Ç–æ, —á—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –≤–µ—Ä–Ω—É–ª API
                }
            )

            for vac in vacancies:
                salary = vac.get("salary") or {}
                currency = salary.get("currency")
                if currency == "RUR":
                    currency = "RUB"

                data["vacancies"].append(
                    {
                        "vacancy_id": vac["id"],
                        "employer_id": emp_id,
                        "name": vac["name"],
                        "salary_from": salary.get("from"),
                        "salary_to": salary.get("to"),
                        "salary_currency": currency,
                        "url": vac["alternate_url"],
                    }
                )
            if declared_open and declared_open != found:
                print(
                    f"‚ö†Ô∏è –£ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—è {emp_name} –∑–∞—è–≤–ª–µ–Ω–æ {declared_open} –≤–∞–∫–∞–Ω—Å–∏–π, "
                    f"–Ω–æ API –≤–µ—Ä–Ω—É–ª {found}"
                )
            else:
                print(
                    f"‚úÖ {emp_name}: —Å–æ–±—Ä–∞–Ω–æ {len(vacancies)} / {found} (–∑–∞—è–≤–ª–µ–Ω–æ {declared_open})"
                )
        return data
